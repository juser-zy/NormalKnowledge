### 数据集介绍

#### 卫星数据
本文所采用的气象卫星数据是2014年于日本发射的向日葵8号新型气象卫星的全圆盘扫描网格数据。该卫星是下一代地球同步气象卫星的先驱，卫星搭载的传感器性能相较于向日葵7号大幅度增加，无论截取观测频率、观测范围、波道、清晰度都大幅改善，大幅强化了卫星云图的质量。
具体来说，对比MTSAT系列，Himawari-8气象卫星将观测通道由五个增加到16个，它具有3个可见光、3个近红外和10个红外通道。并且这个卫星具有更高的时间和空间分辨率，其中可见光通道云图分辨率达到0.5公里，近红外和红外通道云图分辨率达到1到2公里，全盘图观测频率达到每10分钟一次。因此，最大程度地利用这颗卫星，将提高对台风和暴雨的预测精度，为中尺度天气监测和预报提供了一种更加先进更为有效的工具，从而为气象预报、灾害性天气监测提供检定的保障，为相关的决策支持服务、公众服务、科学研究工作提供有效的支持。

#### 雷达数据
在中国中东部地区，单点雷达站间距较为紧密，一般在150千米至200千米左右，这使得雷达数据的时空分辨率相对较高。这样的布局有助于对快速变化的天气现象进行及时监测和准确预测，为气象灾害的预警和应对提供重要支持。
相较之下，中国西部地区的雷达站点间距较大，一般在250千米至300千米左右。这样的间距使得西部地区的雷达数据时空分辨率较低，难以有效捕捉短时强降水、暴雨、台风等极端天气事件的细节和变化。同时，西部地区的地理条件复杂，包括高山、丘陵、沙漠等地形和气候变化，导致雷达数据容易受到干扰和噪声的影响，降低了数据的可靠性和准确性。
因此本文使用的雷达反射率数据，即标签数据，是中国东部地区天气雷达覆盖范围较广的雷达数据，地理分辨率为0.04，时间分辨率为6分钟。

### 数据处理
虽然向日葵八号卫星的传感器包含了多个通道，且每个通道都有自己的独特的观测波段，具有独特的识别信息，承担相应的任务。理论上将所有卫星通道数据信息全部塞入模型会得到更好的结果，但是实际进行训练的时候会产生很多问题。首先，神经网络的宽度会相应增加，在训练前期增加网络宽度虽然可以更好地捕捉数据中的复杂关系，更快学习到数据特征，但是在网络后期，宽度的增加会导致模型过于复杂，无法泛化到新数据，导致模型过拟合。其次，信息的全部汲取会导致网络的训练参数大幅增加，然而现有的硬件设备无法处理如此庞大的数据集，训练会因此龟速进行。此外，部分卫星通道数据信息与雷达反射率关联不大，存在冗余信息，冗余信息的涉入会延缓训练过程甚至导致模型过拟合情况。

因此，在基于卫星数据的雷达反射率反演过程中首先需要对16个通道数据进行筛选。关于卫星通道数据信息的筛选，首先删除通道缺失、时间缺失的数据，然后在查阅相关研究资料后，决定选取7、9、13、15、16五个通道数据，空间分辨率0.02 ，时间分辨率为10分钟，时间范围为2020年到2022年。
其中通道7数据与粒子半径相关，中心波长为3.90 ，主要用于下层云雾观测。
通道9中心波长为6.95 ，主要用于中层水汽程度观测。
通道13中心波长为10.35 ，主要用于云图像和云顶情况观测。
通道15中心波长为12.4，主要用于云的图像、海面水温进行观测。
通道16中心波长为13.30 ，主要用于云层高度测量。
其中，值得注意的是通道16会包含卷云信息，而卷云是高层非降水云，其顶部温度很低，但不会产生降水。然而，通道16饱含反演的重要特征信息，不能舍弃，因此需要尽可能的降低高层非降水云的干扰。查询资料可得，波段间的亮温差也可以表征云的性质信息，便于捕捉强对流区[37]。Kurino[14]使用地球静止气象卫星 GMS-5 (Geostationary Meteorological Satellite) 11 与 12  通道的亮温差来降低高层非降水云的干扰。因此，根据前人的研究[37-39]，本文模型在训练时加入了波长相近的13通道与15通道的亮温差资料。
本文选择的5个卫星通道数据信息相关资料具体如表1所示。
![](images/Pasted%20image%2020230726173620.png)

此外，由于雷达网格数据和卫星网格数据的时间分辨率并不完全相同，但仅仅匹配具有相同时间分辨率的数据会导致训练模型所需的数据样本不足且大气运动在短时间内变化不大，因此本文基于卫星数据的时间戳选择误差在2分钟范围内的雷达网格数据作为标签数据。


### 评价指标介绍

根据相关文献，本文采用五个评价指标来衡量反演模型的性能，分别是海德克技巧评分（HSS）、临界成功指数（CSI）、准确率（ACC）、虚警率（FAR）和命中率（POD）。

为了计算这些评价指标，本文选择了三个不同的阈值，分别为5、20和35。根据这些阈值，将雷达格点数据转换成0，1形式的二进制矩阵，从而计算得到TP（真正例）、FP（假正例）、FN（假负例）和TN（真负例）的值。具体参数含义见表。

这些评价指标可以评估反演模型在识别正例和负例方面的表现。其中，HSS和CSI可以衡量模型的准确性和敏感性，ACC用于评估模型的整体正确率，FAR用于测量模型的虚警程度，而POD则用于评估模型对真实事件的检测能力。通过综合考虑这些指标的结果，我们可以更全面地评估反演模型的性能和有效性。






![](images/Pasted%20image%2020230726211619.png)

![](images/Pasted%20image%2020230726211434.png)
![](images/Pasted%20image%2020230726211443.png)
![](images/Pasted%20image%2020230726211529.png)
### 结果Results
#### Experimental Settings
本文采用联邦平均算法作为分布式训练架构的基础。
考虑到每个存储雷达数据的分站点的特殊性，与移动的分布式训练客户端不同，这些站点所使用的计算机都具备稳定的性能，网络连接实时性高。
因此本模型拟设置C的比例为1，则每一轮全部客户端均参与计算，共有4个clients。设置总的T为5，每一轮T共有10个Epoch。
此外，训练使用的优化器是ADAM优化器，其超参数配置设置为默认值，损失函数采用本文提出的算法，学习率设置为0.001。 
关于实验的具体硬件和软件配置如表所示。
#### Statistical Results
##### train loss
损失函数曲线代表着在训练过程中模型的性能和训练进展。损失函数衡量了模型的预测结果与真实标签之间的差距，也可以看作是模型对训练数据的拟合程度。本文提出的模型在模拟的分站点的5次迭代，每次10个Epoch，共计50个Epoch的损失函数如图所示。

此处为一个客户端的的训练损失函数曲线图。

由图可以看到训练损失函数曲线图整体趋势逐步下降，趋于稳定。值得注意的是，实验时发现训练过程中的模型损失值在10，20，30，40的关键点后的那几个批次训练波动比平常大。大致原因是由于此处为分站点向中央服务器传输模型参数，中央服务器加权平均聚合更新全局模型参数，再将全局模型参数传播给各个站点，更新后的全局模型参数与原本客户端本地的推理的模型参数存在一定差值，从而导致在关键点有波动。但是模型整体稳步下降，逐渐收敛。
此外，第三个客户端相较于其他客户端明显收敛的更快，值更低。经过反复多次验证发现是因为超参数与本地客户端相较于其他匹配的更好。
![](images/Pasted%20image%2020230808135415.png)
##### 参数量统计
关于各个模型的参数量统计如表所示。统一设置Input Size 均为4.07 MB。从参数量角度可以看出，Unet模型表现差的原因大概率是模型过于简单，每层编码层只有两块卷积进行特征学习，学习效果不行。DeepLabv3虽然总参数量少，模型训练中可学习参数包括权重和偏置较少，但是模型使用了大量的复杂操作，大概率是空间金字塔池化和空洞卷积技术，导致模型所需的浮点运算次数过多，导致推理时间更长，需要更多的计算资源，选择具备强大GPU性能的设备。Danet虽然相较于DeepLabv3所需的FLOPs较少，但是总参数量多，需要考虑总参数数量与可用内存之间的平衡。本文提出的UResLham模型需要的总参数量是DeepLabv3的三倍，但是所需的浮点运算综述是它的14.8%，所需的计算资源较少，适合于专用气象数据的服务器，存储容量大、数据吞吐量足够 但是适用于深度学习的设备较少，性能欠佳。
- unet_sr
Total params: 13,484  
Trainable params: 13,484  
Non-trainable params: 0  
Input size (MB): 4.07  
Forward/backward pass size (MB): 799.13  
Params size (MB): 0.05  
Estimated Total Size (MB): 803.25  
FLOPs: 0.795966538 G

- res34unet_cbam
Total params: 49,299,684  
Trainable params: 49,299,684  
Non-trainable params: 0  
Input size (MB): 4.07  
Forward/backward pass size (MB): 2386.03  
Params size (MB): 188.06  
Estimated Total Size (MB): 2578.16  
FLOPs: 126.560044456 G

- res34unet
Total params: 49,211,073  
Trainable params: 49,211,073  
Non-trainable params: 0  
Input size (MB): 4.07  
Forward/backward pass size (MB): 2343.58  
Params size (MB): 187.73  
Estimated Total Size (MB): 2535.37  
FLOPs: 126.548688896 G

- deeplabv3
Total params: 15,316,417  
Trainable params: 15,316,417  
Non-trainable params: 0    
Input size (MB): 4.07  
Forward/backward pass size (MB): 8659.35  
Params size (MB): 58.43  
Estimated Total Size (MB): 8721.84  
FLOPs: 848.8965872 G

- danet
Total params: 66,433,445  
Trainable params: 66,433,445  
Non-trainable params: 0    
Input size (MB): 4.07  
Forward/backward pass size (MB): 9661.05  
Params size (MB): 253.42  
Estimated Total Size (MB): 9918.55  
FLOPs: 298.26996298 G

##### rmse, hss各项指标图片
![](images/Pasted%20image%2020230808162816.png)
![](images/Pasted%20image%2020230808162827.png)
在同样的数据集上，本文使用了U-Net模型、Danet模型、DeepLabv3模型进行了对比实验。为了实验的公正性，所有超参数均设置为本文实验一样的参数，总的迭代数T为5，每一轮T每个client共有10个Epoch，共计50个Epoch。本文选择了三个5、20和35不同的阈值进行相关指标评价，6种评价指标实验结果图如图所示。其中HSS、CSI、ACC、POD均是指标越高，实验结果越好，而RMSE和FAR则是指标越高，效果越差。

------------------

首先针对RMSE指标进行讨论，由于在不同阈值下同一模型的RMSE指标相同，因此上图只列举了阈值为35的RMSE指标。RMSE 是模型预测误差的典型度量，较小的 RMSE 值表示预测值与实际值之间的一致性较好，且RMSE 对异常值较为敏感，因为平方差将放大较大的误差效应。本文提出的模型的RMSE值为3.5，相较于unet的7.7, danet的4.0, DeepLabv3的均有一定指标的降低，性能的提高。

针对FAR指标，几种模型均在阈值为20的时候，FAR最小，在阈值为35的时候FAR最大。造成这种情况的原因大概率是强降水天气为小概率事件，发生的时间间隔长，地点集中在某一区域。至于为何阈值为5的时候FAR也较高是因为模型判断强降水区域，雷达反射率较高区域周围雷达反射率区域，可能存在着轻微降水现象，这也是未来工作需要改进的地方。在阈值为35的时候，相较于其他模型，本文模型分别下降了（35.02，11.74，**还需要一个**）百分点。与这个指标有相同趋势的是HSS指标，只不过HSS指标含义与FAR相反。

针对POD指标，几种模型均在阈值为5的时候，POD最高，在阈值为35的时候POD最小。本文模型在阈值为5的时候值为，相较于其他模型提高了（2.7，0.4，**还需要一个**）几个百分点。在阈值为20和35的时候，几种预测难度加大，本模型的精度也分别降为（0.709，0.647），造成这个现象的原因也是强对流天气小概率事件的特性。不过，相较于其他三种预测模型，在阈值为35的时候提升的百分比最大。与这个指标成相同趋势的是CSI指标。

针对ACC指标，几个模型在阈值为35的时候相差不大，也是因为强对流天气是小概率事件，所占的雷达反射率区域小，基本上都可以预测。但是所有模型在阈值为5，20的时候表现较差，因为雷达反射率低覆盖的范围较大，导致模型预测困难，精度降低。

这些指标这均证明了本研究提出的模型在雷达反射率反演方面相较于其他模型有较大改善，不仅在估计雷达反射率较低区域时表现更好，而且在估计高雷达反射率区域也有显著改善。 

-----------------------

##### 关于分布式造成的损失
本文还将所有客户端数据集中起来进行了相同超参数条件下的集中式训练。集中式训练和采用联邦平均算法的分布式训练的评价指标如图所示。

由图可以看出，采用分布式训练造成的各项指标相对于集中式损失不大。原因是数据经过数据清洗，各客户端数据遵循较为严格的标准，且超参数采用了余弦退火算法调整学习率，虽然这样，但是模型参数依旧会稍逊于集中式训练的参数。



##### 消融实验

此外，为了证明解码层嵌入的轻量级混合注意力层是否有效，本文还做了相同条件下二者的消融实验。首先是二者的损失函数曲线图。

由图可知，没有嵌入混合注意力机制层的损失函数曲线虽然一开始损失值更小，但是后期收敛的速度更慢，并趋向饱和。嵌入后的模型收敛速度更快，且有继续收敛的趋势。

上述表已经有关于二者的参数量统计。由表可知，嵌入了五个轻量级混合注意力模块的网络仅仅在总的参数量上提高了，在浮点运算总数上提高了。但是性能提高了很多。由此可见混合注意力层的轻量性。

下表是二者的评价指标对比。
从上述的表可以看出在不同阈值不同指标下，嵌入混合注意力机制可以有效提高
improve the feature correlation between the decoder
。从而帮助网络更好地学习特征，加速收敛，并提高模型性能。


#### Case Study


图显示了2021年8月11日18:30相同时间点不同方法的反演结果。 

从图上明显可以看出U-Net算法的反演效果最差，只预测到了中间的雷达反射率高的地方，那里具有强降水天气。右下角和左上方均没有预测得到，此外还具有大范围的空报现象。大概率是它的网络层次太少所导致的。

Danet的话右下角和中间区域的强降水天气预测到了，但是上方未预测到且预测错误很多雷达反射率低的地方。DeepLabv3相较于Danet有很大改善，但是强降水区域预测过多，周边一些区域均预测为强降水。Danet和DeepLabv3模型出现此类问题大概率是模型参数过多，需要更多的迭代次数来寻找恰当的权值。

在相同的迭代次数下，URes架构性能更佳，中部，右下还有上面的三块强降水区域均预测出来。但是未添加Lham模块的模型出现了过度预测现象，相比之下，添加了模块的UResLham模型没有出现过度预测，恰到好处的显示了强降水区域。但是本文提出的模型空包现象也较为严重，在观测图的大部分零散雷达反射率较低区域，本文模型预测的图会出现周边团块，代表这一块可能出现轻微细雨。这也是后期需要改进的地方。但总体来说，确实在预测雷达反射率高的区域方面较其他模型有了很大改善。

Case study of a heavy rainfall event on 16 July 2018 from the test dataset showing the model reconstruction results at (a–c) 7:00, (d–f) 8:00, and (g–i) 9:00. The false colors of (a,d,g) are cloud clusters with a BT below 198 K in Band 13 superimposed on a grayscale image. (b,e,h) are the observed CREF values, and (c,f,i) are the reconstructed CREF values.





