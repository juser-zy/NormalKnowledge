联邦分布式学习是一种新兴的机器学习方法，旨在解决数据隐私保护和数据分布不均衡等问题。在传统的集中式机器学习中，所有数据都被收集到一个中心服务器进行模型训练，但这种方法可能涉及到大量用户的敏感数据，引发数据隐私和安全问题。而联邦分布式学习通过将模型的训练过程分布在多个本地设备或服务器上，实现在不共享原始数据的情况下进行模型训练。

联邦分布式学习的基本思想是，将模型的初始化版本发送到每个参与方（例如用户设备或服务器），然后在本地设备上使用本地数据进行训练。在每次训练迭代中，本地设备会计算模型参数的梯度，将梯度信息聚合后发送给中央服务器。中央服务器根据收集到的梯度信息来更新全局模型，并将更新后的模型发送回每个参与方。这个过程会在多个轮次中重复进行，直到模型收敛或达到预定的训练轮次。



中心化联邦学习

FedAvg

联邦学习是一种分布式机器学习技术，其核心思想是通过在多个拥有本地数据的数据源之间进行分布式模型训练，在不需要交换本地个体或样本数据的前提下，仅通过交换模型参数或中间结果的方式，构建基于虚拟融合数据下的全局模型，从而实现数据隐私保护和数据共享计算的平衡，即“数据可用不可见”、“数据不动模型动”的应用新范式。许多客户端（例如移动设备或整个组织）在中央服务器（例如服务提供商）的编排下协同训练一个模型，同时保持训练数据的分散。联邦学习体现了集中数据收集和最小化的原则，可以减轻许多由传统的、集中的机器学习和数据科学方法造成的系统性隐私风险和成本。

![](images/Pasted%20image%2020230729211300.png)
![](images/Pasted%20image%2020230729211320.png)